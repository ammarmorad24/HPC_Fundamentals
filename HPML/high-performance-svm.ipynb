{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "## Explanation of the Code\n",
    "\n",
    "This Jupyter Notebook demonstrates the implementation of a Linear Support Vector Machine (SVM) for binary classification using both PyTorch and scikit-learn. The dataset used is the MNIST dataset, specifically focusing on classifying digits 0 and 1.\n",
    "\n",
    "### Code Breakdown\n",
    "\n",
    "1. **Imports and Dataset Loading (Cell 0 and 1)**:\n",
    "    - Various libraries are imported, including PyTorch, scikit-learn, and others.\n",
    "    - The MNIST dataset is loaded, and only the digits 0 and 1 are selected for binary classification.\n",
    "    - The data is normalized and split into training and testing sets.\n",
    "\n",
    "2. **Data Preparation (Cell 2)**:\n",
    "    - The data is converted to PyTorch tensors and loaded into a DataLoader for batching.\n",
    "\n",
    "3. **Model Definition and Training (Cell 5)**:\n",
    "    - A custom Linear SVM model is defined using PyTorch's `nn.Module`.\n",
    "    - The hinge loss function is defined.\n",
    "    - The model is initialized, and the training loop is executed using Stochastic Gradient Descent (SGD) for optimization.\n",
    "\n",
    "4. **Evaluation (Cell 6)**:\n",
    "    - The trained model is evaluated on the test set, and the accuracy is calculated.\n",
    "\n",
    "5. **Scikit-learn SVM (Cell 7)**:\n",
    "    - A Linear SVM is also trained using scikit-learn for comparison.\n",
    "    - The model is evaluated on the test set, and the accuracy is calculated (so close to the builtin linear)\n",
    "\n",
    "### Leveraging GPU\n",
    "\n",
    "The code leverages GPU for training the PyTorch model by setting the device to GPU if available:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-28T10:57:39.381996Z",
     "iopub.status.busy": "2025-01-28T10:57:39.381651Z",
     "iopub.status.idle": "2025-01-28T10:57:39.387676Z",
     "shell.execute_reply": "2025-01-28T10:57:39.386765Z",
     "shell.execute_reply.started": "2025-01-28T10:57:39.381968Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T10:57:39.389093Z",
     "iopub.status.busy": "2025-01-28T10:57:39.388852Z",
     "iopub.status.idle": "2025-01-28T10:58:08.929907Z",
     "shell.execute_reply": "2025-01-28T10:58:08.928919Z",
     "shell.execute_reply.started": "2025-01-28T10:57:39.389073Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading MNIST dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load MNIST dataset\n",
    "print(\"Loading MNIST dataset...\")\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "\n",
    "# Convert to numpy arrays and normalize\n",
    "X = X.astype(np.float32) / 255.0\n",
    "y = y.astype(np.int32)\n",
    "\n",
    "# Binary classification: classify digit 0 vs digit 1\n",
    "X = X[(y == 0) | (y == 1)]\n",
    "y = y[(y == 0) | (y == 1)]\n",
    "y = np.where(y == 0, -1, 1)  # Convert labels to -1 and 1 for SVM\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T10:58:08.932027Z",
     "iopub.status.busy": "2025-01-28T10:58:08.931711Z",
     "iopub.status.idle": "2025-01-28T10:58:08.951975Z",
     "shell.execute_reply": "2025-01-28T10:58:08.950983Z",
     "shell.execute_reply.started": "2025-01-28T10:58:08.932003Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
    "\n",
    "# Create DataLoader for batching\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T10:58:08.953293Z",
     "iopub.status.busy": "2025-01-28T10:58:08.953054Z",
     "iopub.status.idle": "2025-01-28T10:58:11.175912Z",
     "shell.execute_reply": "2025-01-28T10:58:11.175181Z",
     "shell.execute_reply.started": "2025-01-28T10:58:08.953272Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM...\n",
      "Epoch [1/20], Loss: 0.1048\n",
      "Epoch [2/20], Loss: 0.0268\n",
      "Epoch [3/20], Loss: 0.0198\n",
      "Epoch [4/20], Loss: 0.0158\n",
      "Epoch [5/20], Loss: 0.0134\n",
      "Epoch [6/20], Loss: 0.0117\n",
      "Epoch [7/20], Loss: 0.0103\n",
      "Epoch [8/20], Loss: 0.0094\n",
      "Epoch [9/20], Loss: 0.0087\n",
      "Epoch [10/20], Loss: 0.0079\n",
      "Epoch [11/20], Loss: 0.0075\n",
      "Epoch [12/20], Loss: 0.0069\n",
      "Epoch [13/20], Loss: 0.0066\n",
      "Epoch [14/20], Loss: 0.0061\n",
      "Epoch [15/20], Loss: 0.0059\n",
      "Epoch [16/20], Loss: 0.0056\n",
      "Epoch [17/20], Loss: 0.0054\n",
      "Epoch [18/20], Loss: 0.0051\n",
      "Epoch [19/20], Loss: 0.0048\n",
      "Epoch [20/20], Loss: 0.0047\n"
     ]
    }
   ],
   "source": [
    "# Define SVM model\n",
    "class LinearSVM(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LinearSVM, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)  # Single output for binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x).squeeze()  # Squeeze to remove extra dimension\n",
    "\n",
    "# Define hinge loss\n",
    "def hinge_loss(output, target):\n",
    "    return torch.mean(torch.clamp(1 - output * target, min=0))\n",
    "\n",
    "# Initialize model, optimizer, and hyperparameters\n",
    "input_dim = X_train.shape[1]\n",
    "model = LinearSVM(input_dim).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=0.01)  # L2 regularization\n",
    "num_epochs = 20\n",
    "\n",
    "# Training loop\n",
    "print(\"Training SVM...\")\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = hinge_loss(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T10:58:11.177031Z",
     "iopub.status.busy": "2025-01-28T10:58:11.176707Z",
     "iopub.status.idle": "2025-01-28T10:58:11.182327Z",
     "shell.execute_reply": "2025-01-28T10:58:11.181607Z",
     "shell.execute_reply.started": "2025-01-28T10:58:11.176999Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9973\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor)\n",
    "    predictions = torch.sign(test_outputs)\n",
    "    accuracy = (predictions == y_test_tensor).float().mean()\n",
    "    print(f\"Test Accuracy: {accuracy.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T10:58:11.183297Z",
     "iopub.status.busy": "2025-01-28T10:58:11.183051Z",
     "iopub.status.idle": "2025-01-28T10:58:11.981534Z",
     "shell.execute_reply": "2025-01-28T10:58:11.980597Z",
     "shell.execute_reply.started": "2025-01-28T10:58:11.183263Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM using scikit-learn...\n",
      "Test Accuracy: 0.9993\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the SVM model\n",
    "print(\"Training SVM using scikit-learn...\")\n",
    "svm_model = SVC(kernel='linear', C=1.0)  # Linear SVM\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = svm_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
