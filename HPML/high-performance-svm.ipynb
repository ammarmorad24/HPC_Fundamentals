{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-28T10:57:39.381996Z",
     "iopub.status.busy": "2025-01-28T10:57:39.381651Z",
     "iopub.status.idle": "2025-01-28T10:57:39.387676Z",
     "shell.execute_reply": "2025-01-28T10:57:39.386765Z",
     "shell.execute_reply.started": "2025-01-28T10:57:39.381968Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.5.1-cp312-cp312-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: filelock in /home/ammarmorad/anaconda3/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ammarmorad/anaconda3/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/ammarmorad/anaconda3/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ammarmorad/anaconda3/lib/python3.12/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /home/ammarmorad/anaconda3/lib/python3.12/site-packages (from torch) (2024.12.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/nvidia-cudnn-cu12/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/nvidia-cudnn-cu12/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/nvidia-cudnn-cu12/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/nvidia-cudnn-cu12/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/nvidia-cudnn-cu12/\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/nvidia-cufft-cu12/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/nvidia-cufft-cu12/\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install missing packages\n",
    "%pip install torch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T10:57:39.389093Z",
     "iopub.status.busy": "2025-01-28T10:57:39.388852Z",
     "iopub.status.idle": "2025-01-28T10:58:08.929907Z",
     "shell.execute_reply": "2025-01-28T10:58:08.928919Z",
     "shell.execute_reply.started": "2025-01-28T10:57:39.389073Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading MNIST dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load MNIST dataset\n",
    "print(\"Loading MNIST dataset...\")\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "\n",
    "# Convert to numpy arrays and normalize\n",
    "X = X.astype(np.float32) / 255.0\n",
    "y = y.astype(np.int32)\n",
    "\n",
    "# Binary classification: classify digit 0 vs digit 1\n",
    "X = X[(y == 0) | (y == 1)]\n",
    "y = y[(y == 0) | (y == 1)]\n",
    "y = np.where(y == 0, -1, 1)  # Convert labels to -1 and 1 for SVM\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T10:58:08.932027Z",
     "iopub.status.busy": "2025-01-28T10:58:08.931711Z",
     "iopub.status.idle": "2025-01-28T10:58:08.951975Z",
     "shell.execute_reply": "2025-01-28T10:58:08.950983Z",
     "shell.execute_reply.started": "2025-01-28T10:58:08.932003Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
    "\n",
    "# Create DataLoader for batching\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T10:58:08.953293Z",
     "iopub.status.busy": "2025-01-28T10:58:08.953054Z",
     "iopub.status.idle": "2025-01-28T10:58:11.175912Z",
     "shell.execute_reply": "2025-01-28T10:58:11.175181Z",
     "shell.execute_reply.started": "2025-01-28T10:58:08.953272Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM...\n",
      "Epoch [1/20], Loss: 0.1048\n",
      "Epoch [2/20], Loss: 0.0268\n",
      "Epoch [3/20], Loss: 0.0198\n",
      "Epoch [4/20], Loss: 0.0158\n",
      "Epoch [5/20], Loss: 0.0134\n",
      "Epoch [6/20], Loss: 0.0117\n",
      "Epoch [7/20], Loss: 0.0103\n",
      "Epoch [8/20], Loss: 0.0094\n",
      "Epoch [9/20], Loss: 0.0087\n",
      "Epoch [10/20], Loss: 0.0079\n",
      "Epoch [11/20], Loss: 0.0075\n",
      "Epoch [12/20], Loss: 0.0069\n",
      "Epoch [13/20], Loss: 0.0066\n",
      "Epoch [14/20], Loss: 0.0061\n",
      "Epoch [15/20], Loss: 0.0059\n",
      "Epoch [16/20], Loss: 0.0056\n",
      "Epoch [17/20], Loss: 0.0054\n",
      "Epoch [18/20], Loss: 0.0051\n",
      "Epoch [19/20], Loss: 0.0048\n",
      "Epoch [20/20], Loss: 0.0047\n"
     ]
    }
   ],
   "source": [
    "# Define SVM model\n",
    "class LinearSVM(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LinearSVM, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)  # Single output for binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x).squeeze()  # Squeeze to remove extra dimension\n",
    "\n",
    "# Define hinge loss\n",
    "def hinge_loss(output, target):\n",
    "    return torch.mean(torch.clamp(1 - output * target, min=0))\n",
    "\n",
    "# Initialize model, optimizer, and hyperparameters\n",
    "input_dim = X_train.shape[1]\n",
    "model = LinearSVM(input_dim).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=0.01)  # L2 regularization\n",
    "num_epochs = 20\n",
    "\n",
    "# Training loop\n",
    "print(\"Training SVM...\")\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = hinge_loss(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T10:58:11.177031Z",
     "iopub.status.busy": "2025-01-28T10:58:11.176707Z",
     "iopub.status.idle": "2025-01-28T10:58:11.182327Z",
     "shell.execute_reply": "2025-01-28T10:58:11.181607Z",
     "shell.execute_reply.started": "2025-01-28T10:58:11.176999Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9973\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor)\n",
    "    predictions = torch.sign(test_outputs)\n",
    "    accuracy = (predictions == y_test_tensor).float().mean()\n",
    "    print(f\"Test Accuracy: {accuracy.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T10:58:11.183297Z",
     "iopub.status.busy": "2025-01-28T10:58:11.183051Z",
     "iopub.status.idle": "2025-01-28T10:58:11.981534Z",
     "shell.execute_reply": "2025-01-28T10:58:11.980597Z",
     "shell.execute_reply.started": "2025-01-28T10:58:11.183263Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM using scikit-learn...\n",
      "Test Accuracy: 0.9993\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the SVM model\n",
    "print(\"Training SVM using scikit-learn...\")\n",
    "svm_model = SVC(kernel='linear', C=1.0)  # Linear SVM\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = svm_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
